# -*- coding: utf-8 -*-
"""
Created on Sat Sep 27 01:26:16 2025

@author: Michael Lai
"""
from __future__ import annotations

# -*- coding: utf-8 -*-
"""
Analyze selected data-center vendor tickers with yfinance.
- Uses a hard-coded table (å…¬å¸, è‚¡ç¥¨ä»£ç¢¼)ï¼Œè‡ªå‹•æ‹†åˆ†å¤šé‡ä»£ç¢¼ï¼ˆå¦‚ "TT / IR"ã€æˆ–å«é€—è™Ÿï¼‰
- è¨ˆç®— ä¸€å¤©ã€ ä¸€é€±ã€ ä¸€å€‹æœˆã€ ä¸€å­£ã€ åŠå¹´ã€ ä¸€å¹´ æ¼²è·Œå¹…ï¼ˆä»¥ç‡Ÿæ¥­æ—¥è¿‘ä¼¼ï¼š1,5,22,66,130,260ï¼‰
- ä»¥ yfinance ä¸‹è¼‰ç´„ 3 å¹´æ—¥ç·šï¼ˆè‡ªå‹•ä½¿ç”¨èª¿æ•´æ”¶ç›¤åƒ¹ï¼‰
- è¼¸å‡º Excel èˆ‡ CSV åˆ° ~/Documents/MarketReports èˆ‡ /mnt/data

æ³¨æ„ï¼š
- Schneider Electric åœ¨ yfinance çš„å¸¸ç”¨ä»£ç¢¼ç‚º "SU.PA"ï¼ˆå·´é»Žäº¤æ˜“æ‰€ï¼‰ï¼›è‹¥ä½¿ç”¨ "SU" æœƒæŠ“åˆ° Suncor Energyã€‚
- Daikin OTC: "DAIKY"ã€‚
"""
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import yfinance as yf

# ------------------------------
# 1) åŽŸå§‹æ¸…å–®ï¼ˆä¾ä½ æä¾›çš„è¡¨ï¼‰
# ------------------------------
RAW_ROWS = [
    ("Dell", "DELL"),
    ("HPE", "HPE"),
    ("Super Micro", "SMCI"),
    ("Arista Networks", "ANET"),
    ("Cisco", "CSCO"),
    ("NVIDIA", "NVDA"),
    ("SPX Technologies", "SPXC"),
    ("Johnson Controls", "JCI"),
    ("Trane / Ingersoll Rand", "TT / IR"),
    ("Carrier", "CARR"),
    ("Daikin", "DAIKY"),
    ("Vertiv", "VRT"),
    ("Schneider", "SU"),   # æœƒåœ¨ä¿®æ­£è¡¨ä¸­æ”¹ç‚º SU.PA
    ("Eaton", "ETN"),
]

# ------------------------------
# 2) ä»£ç¢¼ä¿®æ­£ï¼ˆè‹¥éœ€è¦è·¨äº¤æ˜“æ‰€å¸¸è¦‹å¯«æ³•ï¼‰
# ------------------------------
SYMBOL_FIXES: Dict[str, str] = {
    "SU": "SU.PA",   # Schneider Electric on Euronext Paris
    # å…¶ä»–éœ€è¦ä¿®æ­£çš„å¯ä»¥æ”¾é€™è£¡
}

# ------------------------------
# 3) åƒæ•¸è¨­å®š
# ------------------------------
HORIZONS = {
    "1æ—¥": 1,
    "1é€±": 5,
    "1æœˆ": 22,
    "1å­£": 66,   # ç´„ 3 å€‹æœˆï¼ˆ1 å­£ï¼‰
    "åŠå¹´": 130,
    "1å¹´": 260,
}

OUTPUT_DIRS = [
    Path.home() / "Documents" / "MarketReports",
    Path("/mnt/data"),
]

# ------------------------------
# 4) å·¥å…·å‡½å¼
# ------------------------------
SEP_CHARS = ["/", ",", "ã€", "|", " "]


def explode_symbols(name: str, raw_codes: str) -> List[Dict[str, str]]:
    """å°‡ä¸€åˆ—ï¼ˆå…¬å¸, ä»£ç¢¼å­—ä¸²ï¼‰æ‹†æˆå¤šå€‹ä¹¾æ·¨çš„å–®ä¸€ä»£ç¢¼åˆ—ã€‚
    è¿”å›ž [{'å…¬å¸': name, 'Symbol': code}, ...]
    """
    s = raw_codes.strip()
    for sep in ["/", ",", "ã€", "|"]:
        s = s.replace(sep, " ")
    parts = [p.strip() for p in s.split() if p.strip()]
    rows = []
    for p in parts:
        fixed = SYMBOL_FIXES.get(p, p)
        rows.append({"å…¬å¸": name, "Symbol": fixed})
    return rows


def pct_change_by_bdays(closes: pd.Series, bdays: int) -> Optional[float]:
    """å¾žæœ€å¾Œä¸€ç­†æ”¶ç›¤åƒ¹å›žæŽ¨ b å€‹ç‡Ÿæ¥­æ—¥çš„è®ŠåŒ–ç™¾åˆ†æ¯”ã€‚"""
    if closes.empty or not isinstance(closes.index, pd.DatetimeIndex):
        return None
    s = closes.sort_index().dropna()
    if s.size < bdays + 1:
        return None
    last_date = s.index[-1]
    ref_idx = pd.bdate_range(end=last_date, periods=bdays + 1)[0]
    ref = s.loc[:ref_idx]
    if ref.empty:
        return None
    price_now = float(s.iloc[-1])
    price_before = float(ref.iloc[-1])
    if price_before == 0 or np.isnan(price_before):
        return None
    return round((price_now - price_before) / price_before * 100.0, 2)

# ------------------------------
# 5) ä¸»æµç¨‹
# ------------------------------

def main():
    # æº–å‚™å±•é–‹å¾Œçš„ä»£ç¢¼è¡¨
    rows: List[Dict[str, str]] = []
    for name, raw_code in RAW_ROWS:
        rows.extend(explode_symbols(name, raw_code))
    base_df = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)

    results = []
    for _, r in base_df.iterrows():
        comp, sym = r["å…¬å¸"], r["Symbol"]
        try:
            hist = yf.download(sym, period="3y", interval="1d", auto_adjust=True, progress=False)
            if hist.empty or "Close" not in hist.columns:
                print(f"âš ï¸ ç„¡è³‡æ–™ï¼š{sym}")
                continue
            closes = hist["Close"].dropna()
            row = {
                "å…¬å¸": comp,
                "Symbol": sym,
                "æœ€æ–°æ”¶ç›¤æ—¥": closes.index[-1].strftime("%Y-%m-%d"),
                "æœ€æ–°æ”¶ç›¤åƒ¹": round(float(closes.iloc[-1]), 4),
            }
            for label, days in HORIZONS.items():
                row[f"{label}æ¼²è·Œå¹…(%)"] = pct_change_by_bdays(closes, days)
            results.append(row)
        except Exception as e:
            print(f"âš ï¸ ä¸‹è¼‰å¤±æ•— {sym}: {e}")

    if not results:
        print("âŒ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ¨™çš„ï¼Œè«‹æª¢æŸ¥ä»£ç¢¼èˆ‡ç¶²è·¯é€£ç·šã€‚")
        return

    out_df = pd.DataFrame(results)
    # æŽ’åºï¼šé è¨­ä¾ 1å¹´æ¼²è·Œå¹… ç”±é«˜åˆ°ä½Ž
    if "1å¹´æ¼²è·Œå¹…(%)" in out_df.columns:
        out_df = out_df.sort_values("1å¹´æ¼²è·Œå¹…(%)", ascending=False)

    # è¼¸å‡º
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    fname = f"selected_tickers_price_changes_{ts}"

    for d in OUTPUT_DIRS:
        d.mkdir(parents=True, exist_ok=True)
        xls = d / f"{fname}.xlsx"
        csv = d / f"{fname}.csv"
        out_df.to_excel(xls, index=False)
        out_df.to_csv(csv, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²è¼¸å‡ºï¼š{xls}")
        print(f"âœ… å·²è¼¸å‡ºï¼š{csv}")

    # é è¦½åˆ—å°ï¼ˆä¸€å¹´æ¼²å¹…å‰ 12 åï¼‰
    cols = ["å…¬å¸", "Symbol", "1å¹´æ¼²è·Œå¹…(%)", "æœ€æ–°æ”¶ç›¤åƒ¹", "æœ€æ–°æ”¶ç›¤æ—¥"]
    print("\nðŸ“Š ä¸€å¹´æ¼²å¹…å‰ 12 åé è¦½ï¼š")
    with pd.option_context("display.max_rows", 20, "display.max_columns", 20):
        print(out_df[[c for c in cols if c in out_df.columns]].head(12))


if __name__ == "__main__":
    main()
